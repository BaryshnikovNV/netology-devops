# Домашнее задание к занятию "`Инцидент-менеджмент`" - `Барышников Никита`


## Задание 1.
<details>
	<summary></summary>
      <br>

Составьте постмортем на основе реального сбоя системы GitHub в 2018 году.

Информацию о сбое можно изучить по ссылкам ниже:

* [краткое описание на русском языке](https://habr.com/ru/post/427301/);
* [развёрнутое описание на английском языке](https://github.blog/2018-10-30-oct21-post-incident-analysis/).

</details>

### Решение:

| <!-- -->                        | <!-- -->                                                                                                                                                                                    |
|:------------------------------- |:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | 
| **Краткое описание инцедента**  | На нескольких сервисах GitHub.com пострадали несколько сетевых разделов с последующим сбоем базы данных, что привело к появлению непоследовательной информации на веб-сайте GitHub.com.     |
| **Предшествующие события**      | В 22:52 UTC 21 октября плановые работы по техническому обслуживанию по замене вышедшего из строя оптического оборудования 100G.                                                             | 
| **Причина инцидента**           | Потеря связи между сетевым центром на Восточном побережье США и основным центром обработки данных на Восточном побережье США. Связь между этими центрами была восстановлена за 43 секунды.  |
| **Воздействие**                 | Кратковременное отключение вызвало цепочку событий, которые привели к 24 часам и 11 минутам сбоя в обслуживании.                                                                            |
| **Обнаружение**                 | 21 октября 2018 22:54 UTC внутренние системы мониторинга начали генерировать оповещения, указывающие на многочисленные сбои в работе систем.                                                     |
| **Реакция**                     | К 23:02 UTC инженеры из команды быстрого реагирования определили, что топологии для многочисленных кластеров баз данных находятся в неожиданном состоянии. Запрос API Orchestrator показал топологию репликации базы данных, которая включала только серверы из центра обработки данных на Западном побережье США. К 21 октября 2018 23:07 UTC команда реагирования решила вручную заблокировать  внутренний инструмент развертывания, чтобы предотвратить внесение каких-либо дополнительных изменений. В 23:09 UTC команда реагирования перевела сайт в желтый статус. Это действие автоматически перевело ситуацию в активный инцидент и отправило предупреждение координатору инцидента. В 23:11 UTC присоединился координатор инцидентов и двумя минутами позже изменил решение на красный статус. |
| **Восстановление**              | 22 октября 2018 00:05 UTC инженеры, участвующие в группе реагирования на инциденты, приступили к разработке плана устранения несоответствий данных и реализации процедур отработки отказа для MySQL. План состоял в том, чтобы восстановить данные из резервных копий, синхронизировать реплики на обоих сайтах, вернуться к стабильной топологии обслуживания, а затем возобновить обработку заданий, поставленных в очередь. |
| **Таймлайн**                    | 21 октября 2018 22:52 UTC. Потеря связи между сетевым центром на Восточном побережье США и основным центром обработки данных на Восточном побережье США. |
| <!-- -->                        | 21 октября 2018 22:54 UTC. Внутренние системы мониторинга начали генерировать оповещения, указывающие на многочисленные сбои в работе систем. |
| <!-- -->                        | 21 октября 2018 23:02 UTC. Инженеры первой группы реагирования определили, что топологии для многочисленных кластеров БД находятся в неожиданном состоянии. |
| <!-- -->                        | 21 октября 2018 23:07 UTC. Группа реагирования решила вручную заблокировать внутренние средства развёртывания, чтобы предотвратить внесение дополнительных изменений. |
| <!-- -->                        | 21 октября 2018 23:09 UTC. Группа установила [жёлтый статус](https://twitter.com/githubstatus/status/1054147648930897920) работоспособности сайта. |
| <!-- -->                        | 21 октября 2018 23:11 UTC. Координатор инцидентов присоединился к работе и через две минуты принял решение [изменить статус на красный](https://twitter.com/githubstatus/status/1054148705450946560). |
| <!-- -->                        | 21 октября 2018 23:13 UTC. Стало понятно, что проблема затрагивает несколько кластеров БД. |
| <!-- -->                        | 21 октября 2018 23:19 UTC. Запросы о состоянии кластеров БД показали, что необходимо остановить выполнение заданий, которые пишут метаданные типа пуш-запросов. |
| <!-- -->                        | 22 октября 2018 00:05 UTC. Инженеры из группы реагирования начали разрабатывать план устранения несогласованности данных и запустили процедуры отработки отказа для MySQL. План состоял в том, чтобы восстановить файлы из бэкапа, синхронизировать реплики на обоих сайтах, вернуться к стабильной топологии обслуживания, а затем возобновить обработку заданий в очереди. |
| <!-- -->                        | 22 октября 2018 00:41 UTC. К этому времени был инициирован процесс резервного копирования для всех затронутых кластеров MySQL, и инженеры отслеживали прогресс. Одновременно несколько групп инженеров изучали способы ускорения передачи и восстановления без дальнейшей деградации сайта или риска повреждения данных. |
| <!-- -->                        | 22 октября 2018 06:51 UTC. Несколько кластеров в восточном ЦОД завершили восстановление из резервных копий и начали реплицировать новые данные с Западным побережьем. |
| <!-- -->                        | 22 октября 2018 07:46 UTC. GitHub опубликовал [информационное сообщение в блоге](https://github.blog/2018-10-21-october21-incident-report/). |
| <!-- -->                        | 22 октября 2018 11:12 UTC. Все первичные БД вновь переведены на Восток. Это привело к тому, что сайт стал гораздо более отзывчивым, так как записи теперь были направлялись на сервер БД, расположенный в том же физическом ЦОД, что и уровень приложений. Хотя это существенно повысило производительность, всё ещё остались десятки реплик чтения БД, которые отставали от основной копии на несколько часов. |
| <!-- -->                        | 22 октября 2018 13:15 UTC. Приближение к пику нагрузки на GitHub.com. В команде реагирования прошло обсуждение дальнейших действий. Было ясно, что отставание репликации до согласованного состояния увеличивается, а не уменьшается. Ранее была начата подготовка дополнительных реплик чтения MySQL в общедоступном облаке Восточного побережья. Как только они стали доступны, стало легче распределять поток запросов на чтение между несколькими серверами. Уменьшение средней нагрузки на реплики чтения ускорило догон репликации. |
| <!-- -->                        | 22 октября 2018 16:24 UTC. Завершение инхронизации реплик. Возвращение к исходной топологии, устранив проблемы задержки и доступности. В рамках сознательного решения о приоритете целостности данных над быстрым исправлением ситуации был [сохранен красный статус сайта](https://twitter.com/githubstatus/status/1054408042836606977). |
| <!-- -->                        | 22 октября 2018 16:45 UTC. Обработка фоновых задач, накопившихся за время аварии. Удаление устаревших задач. |
| <!-- -->                        | 22 октября 2018 23:03 UTC. Все незавершённые события вебхуков и сборки Pages обработаны, а целостность и правильная работа всех систем подтверждена. Статус сайта [обновлён на зелёный](https://twitter.com/githubstatus/status/1054508689560870912). |
| **Последующие действия**        | Во время восстановления были зафиксированы бинарные логи MySQL c записями в основном ЦОД, которые не реплицировались на западный. Отрегулирована конфигурация Orchestrator, чтобы запретить перемещение первичных БД за границы региона. Ускорена миграция на новую систему отчётности по статусам, которая предоставит более подходящую площадку для обсуждения активных инцидентов более чёткими и ясными формулировками. За несколько недель до этого инцидента была запущена общекорпоративная инженерная инициатива для поддержки обслуживания трафика GitHub из нескольких ЦОД по архитектуре active/active/active. Цель данного проекта — поддержка избыточности N+1 на уровне ЦОД, чтобы выдерживать отказ одного ЦОД без вмешательства со стороны. Начата системная практика проверки сценариев сбоев, прежде чем они возникнут в реальности. |

---